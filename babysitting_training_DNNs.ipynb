{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMghgKyjE295"
      },
      "source": [
        "# **Mount Google drive on colab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8bmO757aqdp",
        "outputId": "6ea38bb8-9575-418d-89e6-19fc9fa5afe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usxEc2-ma-9l",
        "outputId": "1aa9c63d-33c3-426f-f8cd-64e411ee04cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/CV Project 3\n"
          ]
        }
      ],
      "source": [
        "cd '/content/drive/MyDrive/CV Project 3/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-2fGbJHudRk"
      },
      "source": [
        "# **Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKg7tRZpa_lm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from torch import nn\n",
        "import keras \n",
        "#from keras.models import Sequential\n",
        "from keras import layers\n",
        "import sklearn.metrics as metrics\n",
        "from keras import optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision.transforms as T\n",
        "# from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew_VHlHBkrMi",
        "outputId": "817ce461-6580-4f8a-d03c-9a8d39ce32a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Device will determine whether to run the training on GPU or CPU.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltuYK6jzbfTI"
      },
      "source": [
        "# **Step 1** : **Data Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1zjATmQUEA4"
      },
      "outputs": [],
      "source": [
        "# Function to perform Data Augmentation\n",
        "def dataAugmentation(data):\n",
        "  num_imgs = data.shape[0]\n",
        "  temp_tensor = torch.empty((num_imgs*3,3,32,32), dtype=torch.float64)\n",
        "  #print(temp_tensor.shape)\n",
        "  for i in range(num_imgs):            \n",
        "    temp_tensor[i,:,:,:] = torch.flip(data[i,:,:,:], (1,2))\n",
        "    temp_tensor[i+num_imgs,:,:,:] = T.GaussianBlur(kernel_size=(7,7), \n",
        "                                               sigma=(0.1, 0.2))(data[i,:,:,:])\n",
        "    temp_tensor[i+num_imgs*2,:,:] = T.Grayscale(3)(data[i,:,:,:])\n",
        "  return torch.cat((data,temp_tensor))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "w9woOhykbBN9",
        "outputId": "9c8c6e9c-4376-4ec9-ecaf-75aa7a5780ed"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Reading the training dataset - Face and Non-face\n",
        "pos_images_dir = \"ExtractedData/allImages/pos/\"\n",
        "neg_images_dir = \"ExtractedData/allImages/neg/\"\n",
        "pos_img = os.listdir(pos_images_dir)\n",
        "neg_img = os.listdir(neg_images_dir)\n",
        "\n",
        "#Reading the testing dataset - Face and Non-face\n",
        "pos_testimages_dir = \"ExtractedData_chota/ExtractedData/testImages/pos/\"\n",
        "neg_testimages_dir = \"ExtractedData_chota/ExtractedData/testImages/neg/\"\n",
        "pos_test_img = os.listdir(pos_testimages_dir)\n",
        "neg_test_img = os.listdir(neg_testimages_dir)\n",
        "\n",
        "# Count the number of images in each of the training and testing dataset\n",
        "positive_training_image_count = len(pos_img)\n",
        "negative_training_image_count = len(neg_img)\n",
        "positive_testing_image_count = len(pos_test_img)\n",
        "negative_testing_image_count = len(neg_test_img)\n",
        "\n",
        "# Create empty torch.tensors to store training and testing data for each of the Face and Non-Face images\n",
        "Face_img_train = torch.empty((positive_training_image_count,3,32,32), dtype=torch.float64)\n",
        "NonFace_img_train = torch.empty((negative_training_image_count,3,32,32), dtype=torch.float64)\n",
        "Face_img_test = torch.empty((positive_testing_image_count,3,32,32), dtype=torch.float64)\n",
        "NonFace_img_test = torch.empty((negative_testing_image_count,3,32,32), dtype=torch.float64)\n",
        "\n",
        "# Define the classes for classification\n",
        "classes = ('face', 'nonface')\n",
        "\n",
        "# Loading Face training data as torch.tensor\n",
        "for i,pos_image in enumerate (pos_img):\n",
        "    image = cv2.imread(pos_images_dir + pos_image)\n",
        "    image = cv2.resize(image, (32,32))\n",
        "    Face_img_train[i,:,:,:] = T.ToTensor()(image)\n",
        "\n",
        "# Loading Non-Face training data as torch.tensor\n",
        "for i,neg_image in enumerate (neg_img):\n",
        "    image = cv2.imread(neg_images_dir + neg_image)\n",
        "    image = cv2.resize(image, (32,32))\n",
        "    NonFace_img_train[i,:,:,:] = T.ToTensor()(image)\n",
        "\n",
        "# Loading Face Testing images as torch.tensor\n",
        "for i,pos_image in enumerate (pos_test_img):\n",
        "    image = cv2.imread(pos_testimages_dir + pos_image)\n",
        "    image = cv2.resize(image, (32,32))\n",
        "    Face_img_test[i,:,:,:] = T.ToTensor()(image)\n",
        "\n",
        "# Loading Non-Face Testing images as torch.tensor\n",
        "for i,neg_image in enumerate (neg_test_img):\n",
        "    image = cv2.imread(neg_testimages_dir + neg_image)\n",
        "    image = cv2.resize(image, (32,32))\n",
        "    NonFace_img_test[i,:,:,:] = T.ToTensor()(image)\n",
        "\n",
        "# Performing Data Augmentation for training images\n",
        "Face_img_train = dataAugmentation(Face_img_train)\n",
        "NonFace_img_train = dataAugmentation(NonFace_img_train)\n",
        "\n",
        "# Performing Data Augmentation for testing images\n",
        "Face_img_test = dataAugmentation(Face_img_test)\n",
        "NonFace_img_test = dataAugmentation(NonFace_img_test)\n",
        "\n",
        "# Combine the training data for both Face and Non-face in a single tensor\n",
        "training_imgs = torch.cat((Face_img_train,NonFace_img_train))\n",
        "\n",
        "# Combine the testing data for both Face and Non-face in a single tensor\n",
        "testing_imgs = torch.cat((Face_img_test, NonFace_img_test))\n",
        "\n",
        "# Assign labels for both Face and Non-face training data in a single tensor - Assign 1 for Face & 0 for Non-Face\n",
        "training_labels = torch.cat((torch.ones(training_imgs.shape[0]//2), torch.zeros(training_imgs.shape[0]//2)))\n",
        "\n",
        "# Assign labels for both Face and Non-face testing data in a single tensor - Assign 1 for Face & 0 for Non-Face\n",
        "testing_labels = torch.cat((torch.ones(testing_imgs.shape[0]//2), torch.zeros(testing_imgs.shape[0]//2)))\n",
        "\n",
        "# Flatten the training_imgs array for ease of pre-processing\n",
        "training_imgs_flattened = training_imgs.flatten(start_dim=1)\n",
        "\n",
        "# Calculate mean of the training data\n",
        "mean_data = np.mean(np.array(training_imgs_flattened), axis=0)\n",
        "\n",
        "# Calculate standard deviation of the training data\n",
        "std_data = np.std(np.array(training_imgs_flattened), axis=0)\n",
        "\n",
        "##################################################################################################################\n",
        "#                                                                                                                #\n",
        "#                  Step 1 : Data Preprocessing (as per Slide number 4 in project03 description)                  #\n",
        "#                                                                                                                #\n",
        "##################################################################################################################\n",
        "\n",
        "# ================================================================================================================\n",
        "#                               Plotting Training Data : without normalization \n",
        "# ================================================================================================================\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
        "fig.suptitle('Plotting training Data (without normalization)',color = \"red\",fontsize=13)\n",
        "\n",
        "ax1.scatter(training_imgs_flattened[:,0], training_imgs_flattened[:,1], color=\"red\",facecolor='none', s=8)\n",
        "ax1.set_xlim(-2, 2)\n",
        "ax1.set_ylim(-2, 2)\n",
        "ax1.set_title('original data')\n",
        "\n",
        "# Substracting mean from each image to give us a zero-centred data\n",
        "training_imgs_zeroCentred = training_imgs_flattened - mean_data\n",
        "\n",
        "ax2.scatter(training_imgs_zeroCentred[:,0], training_imgs_zeroCentred[:,1], color='green', facecolor='none', s=8)\n",
        "ax2.set_xlim(-2, 2)\n",
        "ax2.set_ylim(-2, 2)\n",
        "ax2.set_title('zero-centered data')\n",
        "\n",
        "# Dividing by standard deviation to give a zero-centred normalized data\n",
        "training_imgs_Normalized = training_imgs_zeroCentred/std_data\n",
        "\n",
        "ax3.scatter(training_imgs_Normalized[:,0], training_imgs_Normalized[:,1], color='blue', facecolor='none', s=8)\n",
        "ax3.set_xlim(-4, 4)\n",
        "ax3.set_ylim(-4, 4)\n",
        "ax3.set_title('normalized data')\n",
        "plt.show()\n",
        "\n",
        "# Calculate mean and standard deviation of all the training images in the dataset\n",
        "for i in range(training_imgs.shape[0]):\n",
        "  mean_data, std_dev_data = training_imgs[i,:,:,:].mean([1,2]), training_imgs[i,:,:,:].std([1,2])\n",
        "  training_imgs[i,:,:,:] = T.Normalize(mean_data, std_dev_data)(training_imgs[i,:,:,:])\n",
        "\n",
        "# Flatten the training_imgs array for ease of pre-processing\n",
        "training_imgs_normalized_flattened = training_imgs.flatten(start_dim=1)\n",
        "\n",
        "# ================================================================================================================\n",
        "#                               Plotting Training Data : with normalization \n",
        "# ================================================================================================================\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
        "fig.suptitle('Plotting training Data (with normalization)',color = \"green\", fontsize=13)\n",
        "ax1.scatter(training_imgs_normalized_flattened[:,0], training_imgs_normalized_flattened[:,1], color=\"red\",facecolor='none', s=8)\n",
        "ax1.set_xlim(-10, 10)\n",
        "ax1.set_ylim(-10, 10)\n",
        "ax1.set_title('original data')\n",
        "\n",
        "# Substracting mean from each image to give us a zero-centred data\n",
        "training_imgs_zeroCentred = training_imgs_normalized_flattened - mean_data[0]\n",
        "\n",
        "ax2.scatter(training_imgs_zeroCentred[:,0], training_imgs_zeroCentred[:,1], color='green', facecolor='none', s=8)\n",
        "ax2.set_xlim(-10, 10)\n",
        "ax2.set_ylim(-10, 10)\n",
        "ax2.set_title('zero-centered data')\n",
        "\n",
        "# Dividing by standard deviation to give a zero-centred normalized data\n",
        "training_imgs_Normalized = training_imgs_zeroCentred/std_dev_data[0]\n",
        "\n",
        "ax3.scatter(training_imgs_Normalized[:,0], training_imgs_Normalized[:,1], color='blue', facecolor='none', s=8)\n",
        "ax3.set_xlim(-25, 25)\n",
        "ax3.set_ylim(-25, 25)\n",
        "ax3.set_title('normalized data')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azn_Jxgkejn3"
      },
      "outputs": [],
      "source": [
        "# Define relevant hyperparameters for training the model\n",
        "batch_size = 1\n",
        "num_classes = 2\n",
        "learning_rate = 0.0005\n",
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhx6tVvHZXNs"
      },
      "outputs": [],
      "source": [
        "# Form the training, validation, and testing dataset using DataLoader class\n",
        "x_train, x_val, y_train, y_val =train_test_split(training_imgs, \n",
        "                                              training_labels, train_size=0.8)\n",
        "train_loader = DataLoader(dataset = ([[x_train[i], y_train[i]] \n",
        "                                      for i in range(len(y_train))]),\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "validation_loader = DataLoader(dataset = ([[x_val[i], y_val[i]] \n",
        "                                           for i in range(len(y_val))]),\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "test_loader = DataLoader(dataset = ([[testing_imgs[i], testing_labels[i]] \n",
        "                                     for i in range(len(testing_labels))]),\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca3aEmX3wDWv"
      },
      "source": [
        "# **Step 2 - Choose the Architecture** :  LeNet \n",
        "\n",
        "The architecture is designed such that it can be used to realise the performance of model with and without batch normalization. We need to make sure that *nn.BatchNorm2d(6)* and *nn.BatchNorm2d(16)* lines of code in the cell below are commented if we want to define the model without any standard regularization method, i.e., batch normalization in our project. Likewise, if we want to get a model with batch normalization, we should make sure that the above line of code remain uncommented.\n",
        "\n",
        "For our demonstration, we keep the batch normalization layer in our model. We used **ReLu activation** function in the model.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgxZI-h7wneT"
      },
      "outputs": [],
      "source": [
        "#Defining the convolutional neural network \n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 6, kernel_size=5, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(6),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.fc = nn.Linear(400, 120)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(120, 84)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(84, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHmeXRlySIT0",
        "outputId": "62052752-3183-48e2-fe00-a448c9c73a5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LeNet5(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc1): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (fc2): Linear(in_features=84, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "net = LeNet5(2).to(device)\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9cNvSHeX-9x"
      },
      "source": [
        "# **Step 3**\n",
        "\n",
        "Checking that the loss is reasonable. For two classes, the loss should be equal to log(2), which is equal to 0.693"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrNNI4_wzh_7",
        "outputId": "d1db8abc-5de4-4b8b-c55a-7ffe4dd13ad4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Printing loss for first epoch\n",
            "Epoch [1/20], Step [960/960], Training Loss: 0.6954\n",
            "Epoch [1/20], Step [240/960], Validation Loss: 0.6655\n"
          ]
        }
      ],
      "source": [
        "# Load the model \n",
        "model = LeNet5(num_classes).to(device)\n",
        "\n",
        "#Setting the loss function\n",
        "cost = nn.CrossEntropyLoss()\n",
        "\n",
        "#Setting the optimizer with the model parameters and learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "total_step = len(train_loader)\n",
        "model = model.double() \n",
        "\n",
        "# Printing training loss \n",
        "for epoch in range(1):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    print (\"Printing loss for first epoch\")\n",
        "    for i, (images, labels) in enumerate(train_loader, 0):  \n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        #Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = cost(outputs, labels.long())\n",
        "        \t\n",
        "        # Backward Propagation and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()*images.size(0)\n",
        "        if (i+1) % 960 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Training Loss: {:.4f}' \n",
        "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, \n",
        "                             loss.item()))\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    for i, (images, labels) in enumerate(validation_loader, 0):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        output = model(images)\n",
        "        loss = cost(output, labels.long())\n",
        "        valid_loss += loss.item()*images.size(0)\n",
        "        if (i+1) % 240 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Validation Loss: {:.4f}' \n",
        "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, \n",
        "                             loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNen03nYds1G"
      },
      "source": [
        "# **Step 4**\n",
        "\n",
        "Adding small regularizer to the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-qmXrRId7H3",
        "outputId": "e5fc5749-6bce-4783-a3fa-f575989d143f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Printing loss for first epoch\n",
            "Epoch [1/20], Step [960/960], Training Loss: 0.7217\n",
            "Epoch [1/20], Step [240/960], Validation Loss: 0.6364\n"
          ]
        }
      ],
      "source": [
        "# Load the model \n",
        "model = LeNet5(num_classes).to(device)\n",
        "\n",
        "#Setting the loss function\n",
        "cost = nn.CrossEntropyLoss()\n",
        "\n",
        "#Setting the optimizer with the model parameters and learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, \n",
        "                            weight_decay=0.0000001)\n",
        "\n",
        "#scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "total_step = len(train_loader)\n",
        "model = model.double() \n",
        "\n",
        "# Printing training loss \n",
        "for epoch in range(1):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    print (\"Printing loss for first epoch\")\n",
        "    for i, (images, labels) in enumerate(train_loader, 0):  \n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        #Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = cost(outputs, labels.long())\n",
        "        \t\n",
        "        # Backward Propagation and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()*images.size(0)\n",
        "        if (i+1) % 960 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Training Loss: {:.4f}' \n",
        "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, \n",
        "                             loss.item()))\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    for i, (images, labels) in enumerate(validation_loader, 0):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        output = model(images)\n",
        "        loss = cost(output, labels.long())\n",
        "        valid_loss += loss.item()*images.size(0)\n",
        "        if (i+1) % 240 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Validation Loss: {:.4f}' \n",
        "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, \n",
        "                             loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR0p6qmMzzQ5"
      },
      "source": [
        "# **Step 5**\n",
        "\n",
        "Overfitting Data - learning rate is tuned and set to 0.03 for overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QOuG8FPuKBD"
      },
      "outputs": [],
      "source": [
        "# Load 20 images in the dataloader to check overfitting\n",
        "overfit_data_loader = DataLoader(dataset = ([[x_train[i], y_train[i]] for i in range(20)]),\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpMEKOUb1elo"
      },
      "outputs": [],
      "source": [
        "# Define relevant hyperparameters for training the model\n",
        "batch_size = 1\n",
        "num_classes = 2\n",
        "learning_rate = 0.03\n",
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBbDPi-A0t7R",
        "outputId": "59d58e0a-0c36-4ae5-b4eb-2c8501fdcf6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "Epoch [1/20], Step [20/960], Training Accuracy: 0.3500, Training Loss: 0.7015\n",
            "Epoch [1/20], Step [20/960], Validation Accuracy: 0.5000, Validation Loss: 0.7321\n",
            "1\n",
            "Epoch [2/20], Step [20/960], Training Accuracy: 0.5000, Training Loss: 0.7423\n",
            "Epoch [2/20], Step [20/960], Validation Accuracy: 0.9000, Validation Loss: 0.6928\n",
            "2\n",
            "Epoch [3/20], Step [20/960], Training Accuracy: 0.6000, Training Loss: 0.6590\n",
            "Epoch [3/20], Step [20/960], Validation Accuracy: 0.7500, Validation Loss: 0.6837\n",
            "3\n",
            "Epoch [4/20], Step [20/960], Training Accuracy: 0.6000, Training Loss: 0.6862\n",
            "Epoch [4/20], Step [20/960], Validation Accuracy: 0.8500, Validation Loss: 0.5782\n",
            "4\n",
            "Epoch [5/20], Step [20/960], Training Accuracy: 0.7500, Training Loss: 0.5671\n",
            "Epoch [5/20], Step [20/960], Validation Accuracy: 0.7000, Validation Loss: 0.3671\n",
            "5\n",
            "Epoch [6/20], Step [20/960], Training Accuracy: 0.7500, Training Loss: 0.1915\n",
            "Epoch [6/20], Step [20/960], Validation Accuracy: 0.6000, Validation Loss: 0.4660\n",
            "6\n",
            "Epoch [7/20], Step [20/960], Training Accuracy: 0.6500, Training Loss: 0.5126\n",
            "Epoch [7/20], Step [20/960], Validation Accuracy: 0.9500, Validation Loss: 0.2525\n",
            "7\n",
            "Epoch [8/20], Step [20/960], Training Accuracy: 0.8000, Training Loss: 1.1810\n",
            "Epoch [8/20], Step [20/960], Validation Accuracy: 0.8500, Validation Loss: 0.2689\n",
            "8\n",
            "Epoch [9/20], Step [20/960], Training Accuracy: 0.8000, Training Loss: 0.1475\n",
            "Epoch [9/20], Step [20/960], Validation Accuracy: 1.0000, Validation Loss: 0.4368\n",
            "9\n",
            "Epoch [10/20], Step [20/960], Training Accuracy: 0.9500, Training Loss: 0.2425\n",
            "Epoch [10/20], Step [20/960], Validation Accuracy: 1.0000, Validation Loss: 0.2010\n",
            "10\n",
            "Epoch [11/20], Step [20/960], Training Accuracy: 1.0000, Training Loss: 0.0073\n",
            "Epoch [11/20], Step [20/960], Validation Accuracy: 1.0000, Validation Loss: 0.0044\n",
            "11\n",
            "Epoch [12/20], Step [20/960], Training Accuracy: 1.0000, Training Loss: 0.0001\n",
            "Epoch [12/20], Step [20/960], Validation Accuracy: 1.0000, Validation Loss: 0.0038\n",
            "12\n",
            "Epoch [13/20], Step [20/960], Training Accuracy: 1.0000, Training Loss: 0.0027\n",
            "Epoch [13/20], Step [20/960], Validation Accuracy: 1.0000, Validation Loss: 0.0001\n",
            "13\n",
            "Epoch [14/20], Step [20/960], Training Accuracy: 1.0000, Training Loss: 0.0029\n",
            "Epoch [14/20], Step [20/960], Validation Accuracy: 1.0000, Validation Loss: 0.0012\n",
            "14\n",
            "Epoch [15/20], Step [20/960], Training Accuracy: 1.0000, Training Loss: 0.0001\n",
            "Epoch [15/20], Step [20/960], Validation Accuracy: 1.0000, Validation Loss: 0.0020\n",
            "15\n",
            "Epoch [16/20], Step [20/960], Training Accuracy: 1.0000, Training Loss: 0.0009\n",
            "Epoch [16/20], Step [20/960], Validation Accuracy: 1.0000, Validation Loss: 0.0030\n",
            "16\n",
            "Epoch [17/20], Step [20/960], Training Accuracy: 1.0000, Training Loss: 0.0000\n",
            "Epoch [17/20], Step [20/960], Validation Accuracy: 1.0000, Validation Loss: 0.0007\n",
            "17\n",
            "Epoch [18/20], Step [20/960], Training Accuracy: 1.0000, Training Loss: 0.0000\n",
            "Epoch [18/20], Step [20/960], Validation Accuracy: 1.0000, Validation Loss: 0.0000\n",
            "18\n",
            "Epoch [19/20], Step [20/960], Training Accuracy: 1.0000, Training Loss: 0.0012\n",
            "Epoch [19/20], Step [20/960], Validation Accuracy: 1.0000, Validation Loss: 0.0000\n",
            "19\n",
            "Epoch [20/20], Step [20/960], Training Accuracy: 1.0000, Training Loss: 0.0017\n",
            "Epoch [20/20], Step [20/960], Validation Accuracy: 1.0000, Validation Loss: 0.0005\n"
          ]
        }
      ],
      "source": [
        "model = LeNet5(num_classes).to(device)\n",
        "\n",
        "#Setting the loss function\n",
        "cost = nn.CrossEntropyLoss()\n",
        "\n",
        "#Setting the optimizer with the model parameters and learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "total_step = len(train_loader)\n",
        "model = model.double() \n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    train_samples = 0.0\n",
        "    valid_samples = 0.0\n",
        "    total, correct = 0 , 0\n",
        "    total_Val, correct_Val = 0 , 0\n",
        "\n",
        "    for i, (images, labels) in enumerate(overfit_data_loader, 0):  \n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        #Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = cost(outputs, labels.long())\n",
        "        \t\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()*images.size(0)\n",
        "        train_samples += images.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total+=labels.size(0)\n",
        "        correct+=(predicted==labels).sum().item()\n",
        "        train_accuracy = float(correct)/len(overfit_data_loader)\n",
        "\n",
        "        if (i+1) % 20 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.4f}, Training Loss: {:.4f}' \n",
        "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, train_accuracy, loss.item()))\n",
        "\n",
        "    model.eval()\n",
        "    for i, (images, labels) in enumerate(overfit_data_loader, 0):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        output = model(images)\n",
        "        loss = cost(output, labels.long())\n",
        "\n",
        "        valid_loss += loss.item()*images.size(0)\n",
        "        train_loss += loss.item()*images.size(0)\n",
        "        valid_samples += images.size(0)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total_Val+=labels.size(0)\n",
        "        correct_Val+=(predicted==labels).sum().item()\n",
        "        val_accuracy = float(correct_Val)/len(overfit_data_loader)\n",
        "        if (i+1) % 20 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Validation Accuracy: {:.4f}, Validation Loss: {:.4f}' \n",
        "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, val_accuracy, loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_c8Cv7U38V2"
      },
      "source": [
        "# **Step 6**\n",
        "\n",
        "Adding small regularization to the model and varying the learning rate that minimizes the loss. Realise the impact of variation of learning rate to vary the loss as required - **getting the loss go down, getting \"nan\" and \"inf\" values**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJBGRMUi4mVP"
      },
      "outputs": [],
      "source": [
        "# Define relevant hyperparameters for training the model\n",
        "# learning rate is varied to find a good value that minimizes the loss.\n",
        "# learning rate = 0.0001 -> Loss is barely changing. Learning rate is too small.\n",
        "# learning rate = 0.0005 -> Loss is comming down \n",
        "# learning rate = 3e6 -> we are getting nan. Learning rate is too high.\n",
        "batch_size = 1\n",
        "num_classes = 2\n",
        "learning_rate = 3e-6\n",
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suDLyWaX4U1l",
        "outputId": "241d2e7b-5212-4786-96d7-1e30c3070836"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Step [960/960], Training Loss: 0.7537\n",
            "Epoch [1/20], Step [240/960], Validation Loss: 0.6287\n",
            "Epoch [2/20], Step [960/960], Training Loss: 0.6458\n",
            "Epoch [2/20], Step [240/960], Validation Loss: 0.7437\n",
            "Epoch [3/20], Step [960/960], Training Loss: 0.7443\n",
            "Epoch [3/20], Step [240/960], Validation Loss: 0.7559\n",
            "Epoch [4/20], Step [960/960], Training Loss: 0.7357\n",
            "Epoch [4/20], Step [240/960], Validation Loss: 0.6434\n",
            "Epoch [5/20], Step [960/960], Training Loss: 0.7423\n",
            "Epoch [5/20], Step [240/960], Validation Loss: 0.6369\n",
            "Epoch [6/20], Step [960/960], Training Loss: 0.7258\n",
            "Epoch [6/20], Step [240/960], Validation Loss: 0.6405\n",
            "Epoch [7/20], Step [960/960], Training Loss: 0.7382\n",
            "Epoch [7/20], Step [240/960], Validation Loss: 0.7328\n",
            "Epoch [8/20], Step [960/960], Training Loss: 0.7389\n",
            "Epoch [8/20], Step [240/960], Validation Loss: 0.7369\n",
            "Epoch [9/20], Step [960/960], Training Loss: 0.7289\n",
            "Epoch [9/20], Step [240/960], Validation Loss: 0.6333\n",
            "Epoch [10/20], Step [960/960], Training Loss: 0.7417\n",
            "Epoch [10/20], Step [240/960], Validation Loss: 0.7376\n",
            "Epoch [11/20], Step [960/960], Training Loss: 0.6555\n",
            "Epoch [11/20], Step [240/960], Validation Loss: 0.7493\n",
            "Epoch [12/20], Step [960/960], Training Loss: 0.6502\n",
            "Epoch [12/20], Step [240/960], Validation Loss: 0.6309\n",
            "Epoch [13/20], Step [960/960], Training Loss: 0.6401\n",
            "Epoch [13/20], Step [240/960], Validation Loss: 0.7301\n",
            "Epoch [14/20], Step [960/960], Training Loss: 0.7268\n",
            "Epoch [14/20], Step [240/960], Validation Loss: 0.6387\n",
            "Epoch [15/20], Step [960/960], Training Loss: 0.6525\n",
            "Epoch [15/20], Step [240/960], Validation Loss: 0.6423\n",
            "Epoch [16/20], Step [960/960], Training Loss: 0.7467\n",
            "Epoch [16/20], Step [240/960], Validation Loss: 0.6646\n",
            "Epoch [17/20], Step [960/960], Training Loss: 0.6474\n",
            "Epoch [17/20], Step [240/960], Validation Loss: 0.7458\n",
            "Epoch [18/20], Step [960/960], Training Loss: 0.7457\n",
            "Epoch [18/20], Step [240/960], Validation Loss: 0.7314\n",
            "Epoch [19/20], Step [960/960], Training Loss: 0.7404\n",
            "Epoch [19/20], Step [240/960], Validation Loss: 0.6374\n",
            "Epoch [20/20], Step [960/960], Training Loss: 0.7461\n",
            "Epoch [20/20], Step [240/960], Validation Loss: 0.7461\n"
          ]
        }
      ],
      "source": [
        "# Load the model \n",
        "model = LeNet5(num_classes).to(device)\n",
        "\n",
        "#Setting the loss function\n",
        "cost = nn.CrossEntropyLoss()\n",
        "\n",
        "#Setting the optimizer with the model parameters and learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, \n",
        "                            weight_decay=0.0000001)\n",
        "\n",
        "#scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "total_step = len(train_loader)\n",
        "model = model.double() \n",
        "\n",
        "# Printing training loss \n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    for i, (images, labels) in enumerate(train_loader, 0):  \n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        #Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = cost(outputs, labels.long())\n",
        "        \t\n",
        "        # Backward Propagation and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()*images.size(0)\n",
        "        if (i+1) % 960 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Training Loss: {:.4f}' \n",
        "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, \n",
        "                             loss.item()))\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    for i, (images, labels) in enumerate(validation_loader, 0):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        output = model(images)\n",
        "        loss = cost(output, labels.long())\n",
        "        valid_loss += loss.item()*images.size(0)\n",
        "        if (i+1) % 240 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Validation Loss: {:.4f}' \n",
        "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, \n",
        "                             loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5esluIy2zag"
      },
      "source": [
        "# **Step 7 :** **Testing the model's performance**\n",
        "\n",
        "Evaluating the performance of the model on the testing data from the FDDB dataset with and without Standard regularization. Here we are using Batch Normalization. \n",
        "\n",
        "**Note**\n",
        "\n",
        "*Results for Batch Normalization can be obtained by uncommenting 2 lines of code in the network architecture defined in Step (2). Commented lines are also shown below*\n",
        "\n",
        "\n",
        "1.   nn.BatchNorm2d(6)\n",
        "2.   nn.BatchNorm2d(16)\n",
        "\n",
        "After this, please run the code in the first cell defined in  Step (2) and then run all the cells in step (7) to get the Testing Accuracy\n",
        "\n",
        "\n",
        "Now, the model with batch normalization is active, i.e, both the above listed lines of code are uncommented in the architecture defined in step (2). In order to view results for the model without Batch Normalization, these lines need to be commented back."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnwL9lhD3I-6"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "def Calculate_accuracy_TestDataset(model, test_loader):\n",
        "  with torch.no_grad():\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for images, labels in test_loader:\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "      print('Accuracy of the network on the test images: {} %'.format(100 * correct / total))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7MCy2J65dFV"
      },
      "outputs": [],
      "source": [
        "# Define relevant hyperparameters for training the model\n",
        "batch_size = 1\n",
        "num_classes = 2\n",
        "learning_rate = 0.00065\n",
        "num_epochs = 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvnEuxfW5PK7",
        "outputId": "7f0c6aee-3f8d-4b81-ee28-fabd8f02ba88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/7], Step [960/960], Training Accuracy: 0.7177, Training Loss: 0.5302\n",
            "Epoch [1/7], Step [240/960], Validation Accuracy: 0.7833, Validation Loss: 0.5793\n",
            "Epoch [2/7], Step [960/960], Training Accuracy: 0.8021, Training Loss: 1.2066\n",
            "Epoch [2/7], Step [240/960], Validation Accuracy: 0.8833, Validation Loss: 0.0471\n",
            "Epoch [3/7], Step [960/960], Training Accuracy: 0.9052, Training Loss: 0.0395\n",
            "Epoch [3/7], Step [240/960], Validation Accuracy: 0.9250, Validation Loss: 0.0709\n",
            "Epoch [4/7], Step [960/960], Training Accuracy: 0.9563, Training Loss: 0.3966\n",
            "Epoch [4/7], Step [240/960], Validation Accuracy: 0.9667, Validation Loss: 0.0134\n",
            "Epoch [5/7], Step [960/960], Training Accuracy: 0.9667, Training Loss: 0.0010\n",
            "Epoch [5/7], Step [240/960], Validation Accuracy: 0.9792, Validation Loss: 0.2471\n",
            "Epoch [6/7], Step [960/960], Training Accuracy: 0.9865, Training Loss: 0.0017\n",
            "Epoch [6/7], Step [240/960], Validation Accuracy: 0.9667, Validation Loss: 0.4276\n",
            "Epoch [7/7], Step [960/960], Training Accuracy: 0.9896, Training Loss: 0.0068\n",
            "Epoch [7/7], Step [240/960], Validation Accuracy: 0.9792, Validation Loss: 0.0002\n"
          ]
        }
      ],
      "source": [
        "model = LeNet5(num_classes).to(device)\n",
        "\n",
        "#Setting the loss function\n",
        "cost = nn.CrossEntropyLoss()\n",
        "\n",
        "#Setting the optimizer with the model parameters and learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, \n",
        "                            weight_decay=1e-5)\n",
        "\n",
        "total_step = len(train_loader)\n",
        "model = model.double() \n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    train_samples = 0.0\n",
        "    valid_samples = 0.0\n",
        "    total, correct = 0 , 0\n",
        "    total_Val, correct_Val = 0 , 0\n",
        "    for i, (images, labels) in enumerate(train_loader, 0):  \n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        #Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = cost(outputs, labels.long())\n",
        "        \t\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()*images.size(0)\n",
        "        train_samples += images.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total+=labels.size(0)\n",
        "        correct+=(predicted==labels).sum().item()\n",
        "        train_accuracy = float(correct)/len(train_loader)\n",
        "\n",
        "        if (i+1) % 960 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.4f}, Training Loss: {:.4f}' \n",
        "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, train_accuracy, loss.item()))\n",
        "\n",
        "    model.eval()\n",
        "    for i, (images, labels) in enumerate(validation_loader, 0):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        output = model(images)\n",
        "        loss = cost(output, labels.long())\n",
        "\n",
        "        valid_loss += loss.item()*images.size(0)\n",
        "        train_loss += loss.item()*images.size(0)\n",
        "        valid_samples += images.size(0)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total_Val+=labels.size(0)\n",
        "        correct_Val+=(predicted==labels).sum().item()\n",
        "        val_accuracy = float(correct_Val)/len(validation_loader)\n",
        "        if (i+1) % 240 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Validation Accuracy: {:.4f}, Validation Loss: {:.4f}' \n",
        "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, val_accuracy, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIfxmYJu4ECy",
        "outputId": "bd03d807-7ef4-4acb-c2cd-b2d44f6e023c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 91.75 %\n"
          ]
        }
      ],
      "source": [
        "Calculate_accuracy_TestDataset(model,test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA3OxGIzKW_f"
      },
      "source": [
        "# **Step 8 :**  **Cross-validation Strategy**\n",
        "\n",
        "PyTorch provides several methods to adjust the learning rate based on the number of epochs. In this project, we are using **ReduceLROnPlateau** scheduler to optimize learning rate.\n",
        "\n",
        "This type of scheduler reduces learning rate when a metric has stopped improving. Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This scheduler reads a metrics quantity and if no improvement is seen for a patience number of epochs, the learning rate is reduced.\n",
        "\n",
        "The argument \"*patience = 5*\" means that the scheduler will check if validation loss does not decrease for 5 epochs, the scheduler decreases the learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ejvyly3HLyxT"
      },
      "outputs": [],
      "source": [
        "# Define relevant hyperparameters for training the model\n",
        "batch_size = 1\n",
        "num_classes = 2\n",
        "learning_rate = 0.00055\n",
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tKysNgPmXHd",
        "outputId": "46d21b65-459e-4755-90e6-f55aea6fa4d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Step [960/960], Training Accuracy: 0.6896, Training Loss: 0.6388\n",
            "Epoch [1/20], Step [240/960], Validation Accuracy: 0.7958, Validation Loss: 0.5726\n",
            "Current Learning Rate :  0.00055\n",
            "Epoch [2/20], Step [960/960], Training Accuracy: 0.8104, Training Loss: 0.1607\n",
            "Epoch [2/20], Step [240/960], Validation Accuracy: 0.8792, Validation Loss: 0.2551\n",
            "Current Learning Rate :  0.00055\n",
            "Epoch [3/20], Step [960/960], Training Accuracy: 0.8833, Training Loss: 0.1005\n",
            "Epoch [3/20], Step [240/960], Validation Accuracy: 0.9458, Validation Loss: 0.0354\n",
            "Current Learning Rate :  0.00055\n",
            "Epoch [4/20], Step [960/960], Training Accuracy: 0.9333, Training Loss: 0.0102\n",
            "Epoch [4/20], Step [240/960], Validation Accuracy: 0.9542, Validation Loss: 0.1212\n",
            "Current Learning Rate :  0.00055\n",
            "Epoch [5/20], Step [960/960], Training Accuracy: 0.9646, Training Loss: 0.0180\n",
            "Epoch [5/20], Step [240/960], Validation Accuracy: 0.9792, Validation Loss: 0.0029\n",
            "Current Learning Rate :  0.00055\n",
            "Epoch [6/20], Step [960/960], Training Accuracy: 0.9760, Training Loss: 0.0061\n",
            "Epoch [6/20], Step [240/960], Validation Accuracy: 0.9750, Validation Loss: 0.0186\n",
            "Current Learning Rate :  0.00055\n",
            "Epoch [7/20], Step [960/960], Training Accuracy: 0.9771, Training Loss: 0.0027\n",
            "Epoch [7/20], Step [240/960], Validation Accuracy: 0.9917, Validation Loss: 0.2230\n",
            "Current Learning Rate :  0.00055\n",
            "Epoch [8/20], Step [960/960], Training Accuracy: 0.9927, Training Loss: 0.0035\n",
            "Epoch [8/20], Step [240/960], Validation Accuracy: 0.9458, Validation Loss: 0.0019\n",
            "Current Learning Rate :  0.00055\n",
            "Epoch [9/20], Step [960/960], Training Accuracy: 0.9917, Training Loss: 0.0014\n",
            "Epoch [9/20], Step [240/960], Validation Accuracy: 0.9875, Validation Loss: 0.2804\n",
            "Current Learning Rate :  0.00055\n",
            "Epoch [10/20], Step [960/960], Training Accuracy: 0.9948, Training Loss: 0.0138\n",
            "Epoch [10/20], Step [240/960], Validation Accuracy: 0.9875, Validation Loss: 0.0000\n",
            "Current Learning Rate :  0.00055\n",
            "Epoch [11/20], Step [960/960], Training Accuracy: 0.9990, Training Loss: 0.0000\n",
            "Epoch [11/20], Step [240/960], Validation Accuracy: 0.9833, Validation Loss: 0.0000\n",
            "Current Learning Rate :  0.00055\n",
            "Epoch [12/20], Step [960/960], Training Accuracy: 1.0000, Training Loss: 0.0048\n",
            "Epoch [12/20], Step [240/960], Validation Accuracy: 0.9917, Validation Loss: 0.0004\n",
            "Current Learning Rate :  5.500000000000001e-05\n",
            "Epoch [13/20], Step [960/960], Training Accuracy: 1.0000, Training Loss: 0.0000\n",
            "Epoch [13/20], Step [240/960], Validation Accuracy: 0.9917, Validation Loss: 0.0035\n",
            "Current Learning Rate :  5.500000000000001e-05\n",
            "Epoch [14/20], Step [960/960], Training Accuracy: 1.0000, Training Loss: 0.0002\n",
            "Epoch [14/20], Step [240/960], Validation Accuracy: 0.9917, Validation Loss: 0.0003\n",
            "Current Learning Rate :  5.500000000000001e-05\n",
            "Epoch [15/20], Step [960/960], Training Accuracy: 1.0000, Training Loss: 0.0041\n",
            "Epoch [15/20], Step [240/960], Validation Accuracy: 0.9917, Validation Loss: 0.3142\n",
            "Current Learning Rate :  5.500000000000001e-05\n",
            "Epoch [16/20], Step [960/960], Training Accuracy: 1.0000, Training Loss: 0.0171\n",
            "Epoch [16/20], Step [240/960], Validation Accuracy: 0.9917, Validation Loss: 0.0000\n",
            "Current Learning Rate :  5.500000000000001e-05\n",
            "Epoch [17/20], Step [960/960], Training Accuracy: 1.0000, Training Loss: 0.0010\n",
            "Epoch [17/20], Step [240/960], Validation Accuracy: 0.9917, Validation Loss: 0.0001\n",
            "Current Learning Rate :  5.5000000000000016e-06\n",
            "Epoch [18/20], Step [960/960], Training Accuracy: 1.0000, Training Loss: 0.0000\n",
            "Epoch [18/20], Step [240/960], Validation Accuracy: 0.9917, Validation Loss: 0.0046\n",
            "Current Learning Rate :  5.5000000000000016e-06\n",
            "Epoch [19/20], Step [960/960], Training Accuracy: 1.0000, Training Loss: 0.0040\n",
            "Epoch [19/20], Step [240/960], Validation Accuracy: 0.9917, Validation Loss: 0.0000\n",
            "Current Learning Rate :  5.5000000000000016e-06\n",
            "Epoch [20/20], Step [960/960], Training Accuracy: 1.0000, Training Loss: 0.0000\n",
            "Epoch [20/20], Step [240/960], Validation Accuracy: 0.9917, Validation Loss: 0.0000\n",
            "Current Learning Rate :  5.5000000000000016e-06\n"
          ]
        }
      ],
      "source": [
        "model = LeNet5(num_classes).to(device)\n",
        "\n",
        "# Setting the loss function\n",
        "cost = nn.CrossEntropyLoss()\n",
        "\n",
        "# Setting the optimizer with the model parameters and learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, \n",
        "                            weight_decay=1e-5)\n",
        "\n",
        "# Adding ReduceLROnPlateau to vary learning rate. \n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', patience = 3)\n",
        "\n",
        "total_step = len(train_loader)\n",
        "model = model.double() \n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    train_samples = 0.0\n",
        "    valid_samples = 0.0\n",
        "    total, correct = 0 , 0\n",
        "    total_Val, correct_Val = 0 , 0\n",
        "    for i, (images, labels) in enumerate(train_loader, 0):  \n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = cost(outputs, labels.long())\n",
        "        \t\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()*images.size(0)\n",
        "        train_samples += images.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total+=labels.size(0)\n",
        "        correct+=(predicted==labels).sum().item()\n",
        "        train_accuracy = float(correct)/len(train_loader)\n",
        "\n",
        "        if (i+1) % 960 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.4f}, Training Loss: {:.4f}' \n",
        "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, train_accuracy, loss.item()))\n",
        "\n",
        "    model.eval()\n",
        "    for i, (images, labels) in enumerate(validation_loader, 0):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        output = model(images)\n",
        "        loss = cost(output, labels.long())\n",
        "\n",
        "        valid_loss += loss.item()*images.size(0)\n",
        "        train_loss += loss.item()*images.size(0)\n",
        "        valid_samples += images.size(0)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total_Val+=labels.size(0)\n",
        "        correct_Val+=(predicted==labels).sum().item()\n",
        "        val_accuracy = float(correct_Val)/len(validation_loader)\n",
        "        if (i+1) % 240 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Validation Accuracy: {:.4f}, Validation Loss: {:.4f}' \n",
        "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, val_accuracy, loss.item()))\n",
        "    curr_lr = optimizer.param_groups[0]['lr']\n",
        "    print('Current Learning Rate : ', curr_lr)\n",
        "\n",
        "    # Passing validation_loss as an argument for checking upto 5 number of epochs.\n",
        "    # patience = 5 means that the scheduler will check if validation loss does not\n",
        "    # decrease for 5 epochs, the scheduler decreases the learning rate\n",
        "    scheduler.step(valid_loss/len(validation_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5Vjm23muyc6"
      },
      "source": [
        "Calculate accuracy on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSW9CtzHq_nN",
        "outputId": "98ee7b89-5512-48a8-ffc7-ee69655a72ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 61.25 %\n"
          ]
        }
      ],
      "source": [
        "Calculate_accuracy_TestDataset(model,test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsoPBGOJ4GJ2"
      },
      "outputs": [],
      "source": [
        "# Define relevant hyperparameters for training the model\n",
        "batch_size = 1\n",
        "num_classes = 2\n",
        "learning_rate = 0.000045\n",
        "num_epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVsSCYwX4Ppe",
        "outputId": "ac00e009-bfd7-46ce-e2fc-060c8aed07db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Step [960/960], Training Accuracy: 0.5771, Training Loss: 0.6007\n",
            "Epoch [1/50], Step [240/960], Validation Accuracy: 0.5292, Validation Loss: 0.6159\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [2/50], Step [960/960], Training Accuracy: 0.5979, Training Loss: 0.6483\n",
            "Epoch [2/50], Step [240/960], Validation Accuracy: 0.6167, Validation Loss: 0.5919\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [3/50], Step [960/960], Training Accuracy: 0.6594, Training Loss: 0.5269\n",
            "Epoch [3/50], Step [240/960], Validation Accuracy: 0.6833, Validation Loss: 0.6890\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [4/50], Step [960/960], Training Accuracy: 0.7083, Training Loss: 0.5606\n",
            "Epoch [4/50], Step [240/960], Validation Accuracy: 0.6917, Validation Loss: 0.7704\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [5/50], Step [960/960], Training Accuracy: 0.7427, Training Loss: 0.6395\n",
            "Epoch [5/50], Step [240/960], Validation Accuracy: 0.7417, Validation Loss: 0.6317\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [6/50], Step [960/960], Training Accuracy: 0.7958, Training Loss: 0.6295\n",
            "Epoch [6/50], Step [240/960], Validation Accuracy: 0.8208, Validation Loss: 0.7126\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [7/50], Step [960/960], Training Accuracy: 0.8146, Training Loss: 0.6730\n",
            "Epoch [7/50], Step [240/960], Validation Accuracy: 0.8542, Validation Loss: 0.7173\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [8/50], Step [960/960], Training Accuracy: 0.8260, Training Loss: 0.5895\n",
            "Epoch [8/50], Step [240/960], Validation Accuracy: 0.8583, Validation Loss: 0.6398\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [9/50], Step [960/960], Training Accuracy: 0.8365, Training Loss: 0.5465\n",
            "Epoch [9/50], Step [240/960], Validation Accuracy: 0.8708, Validation Loss: 0.5805\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [10/50], Step [960/960], Training Accuracy: 0.8510, Training Loss: 0.5211\n",
            "Epoch [10/50], Step [240/960], Validation Accuracy: 0.8667, Validation Loss: 0.6172\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [11/50], Step [960/960], Training Accuracy: 0.8500, Training Loss: 0.1998\n",
            "Epoch [11/50], Step [240/960], Validation Accuracy: 0.8625, Validation Loss: 0.4413\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [12/50], Step [960/960], Training Accuracy: 0.8562, Training Loss: 0.1209\n",
            "Epoch [12/50], Step [240/960], Validation Accuracy: 0.8875, Validation Loss: 0.3971\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [13/50], Step [960/960], Training Accuracy: 0.8604, Training Loss: 0.4210\n",
            "Epoch [13/50], Step [240/960], Validation Accuracy: 0.8917, Validation Loss: 0.2456\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [14/50], Step [960/960], Training Accuracy: 0.8677, Training Loss: 0.2278\n",
            "Epoch [14/50], Step [240/960], Validation Accuracy: 0.8958, Validation Loss: 0.0745\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [15/50], Step [960/960], Training Accuracy: 0.8760, Training Loss: 0.1678\n",
            "Epoch [15/50], Step [240/960], Validation Accuracy: 0.9000, Validation Loss: 0.1258\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [16/50], Step [960/960], Training Accuracy: 0.8906, Training Loss: 0.1315\n",
            "Epoch [16/50], Step [240/960], Validation Accuracy: 0.9000, Validation Loss: 0.4535\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [17/50], Step [960/960], Training Accuracy: 0.8938, Training Loss: 0.6405\n",
            "Epoch [17/50], Step [240/960], Validation Accuracy: 0.9083, Validation Loss: 0.0826\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [18/50], Step [960/960], Training Accuracy: 0.8990, Training Loss: 0.2775\n",
            "Epoch [18/50], Step [240/960], Validation Accuracy: 0.9167, Validation Loss: 0.0799\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [19/50], Step [960/960], Training Accuracy: 0.9094, Training Loss: 0.3321\n",
            "Epoch [19/50], Step [240/960], Validation Accuracy: 0.9167, Validation Loss: 0.6312\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [20/50], Step [960/960], Training Accuracy: 0.9125, Training Loss: 0.3861\n",
            "Epoch [20/50], Step [240/960], Validation Accuracy: 0.9250, Validation Loss: 0.4143\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [21/50], Step [960/960], Training Accuracy: 0.9115, Training Loss: 0.0327\n",
            "Epoch [21/50], Step [240/960], Validation Accuracy: 0.9250, Validation Loss: 0.0342\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [22/50], Step [960/960], Training Accuracy: 0.9187, Training Loss: 0.0665\n",
            "Epoch [22/50], Step [240/960], Validation Accuracy: 0.9250, Validation Loss: 0.7265\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [23/50], Step [960/960], Training Accuracy: 0.9187, Training Loss: 0.1740\n",
            "Epoch [23/50], Step [240/960], Validation Accuracy: 0.9292, Validation Loss: 0.0319\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [24/50], Step [960/960], Training Accuracy: 0.9260, Training Loss: 0.0045\n",
            "Epoch [24/50], Step [240/960], Validation Accuracy: 0.9375, Validation Loss: 0.0793\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [25/50], Step [960/960], Training Accuracy: 0.9344, Training Loss: 0.0944\n",
            "Epoch [25/50], Step [240/960], Validation Accuracy: 0.9375, Validation Loss: 0.0710\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [26/50], Step [960/960], Training Accuracy: 0.9365, Training Loss: 0.0041\n",
            "Epoch [26/50], Step [240/960], Validation Accuracy: 0.9375, Validation Loss: 0.1650\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [27/50], Step [960/960], Training Accuracy: 0.9427, Training Loss: 0.0343\n",
            "Epoch [27/50], Step [240/960], Validation Accuracy: 0.9458, Validation Loss: 0.7312\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [28/50], Step [960/960], Training Accuracy: 0.9479, Training Loss: 0.6450\n",
            "Epoch [28/50], Step [240/960], Validation Accuracy: 0.9417, Validation Loss: 0.1516\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [29/50], Step [960/960], Training Accuracy: 0.9500, Training Loss: 0.0208\n",
            "Epoch [29/50], Step [240/960], Validation Accuracy: 0.9417, Validation Loss: 1.5722\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [30/50], Step [960/960], Training Accuracy: 0.9531, Training Loss: 0.0831\n",
            "Epoch [30/50], Step [240/960], Validation Accuracy: 0.9667, Validation Loss: 0.0262\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [31/50], Step [960/960], Training Accuracy: 0.9552, Training Loss: 0.0354\n",
            "Epoch [31/50], Step [240/960], Validation Accuracy: 0.9458, Validation Loss: 0.0129\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [32/50], Step [960/960], Training Accuracy: 0.9604, Training Loss: 0.0011\n",
            "Epoch [32/50], Step [240/960], Validation Accuracy: 0.9458, Validation Loss: 0.0008\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [33/50], Step [960/960], Training Accuracy: 0.9615, Training Loss: 0.1931\n",
            "Epoch [33/50], Step [240/960], Validation Accuracy: 0.9542, Validation Loss: 0.0116\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [34/50], Step [960/960], Training Accuracy: 0.9677, Training Loss: 0.0146\n",
            "Epoch [34/50], Step [240/960], Validation Accuracy: 0.9667, Validation Loss: 0.0379\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [35/50], Step [960/960], Training Accuracy: 0.9677, Training Loss: 0.0002\n",
            "Epoch [35/50], Step [240/960], Validation Accuracy: 0.9667, Validation Loss: 0.0736\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [36/50], Step [960/960], Training Accuracy: 0.9698, Training Loss: 0.1696\n",
            "Epoch [36/50], Step [240/960], Validation Accuracy: 0.9583, Validation Loss: 0.2467\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [37/50], Step [960/960], Training Accuracy: 0.9760, Training Loss: 0.0055\n",
            "Epoch [37/50], Step [240/960], Validation Accuracy: 0.9708, Validation Loss: 0.0002\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [38/50], Step [960/960], Training Accuracy: 0.9812, Training Loss: 0.0668\n",
            "Epoch [38/50], Step [240/960], Validation Accuracy: 0.9667, Validation Loss: 0.0014\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [39/50], Step [960/960], Training Accuracy: 0.9802, Training Loss: 0.0174\n",
            "Epoch [39/50], Step [240/960], Validation Accuracy: 0.9750, Validation Loss: 0.0025\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [40/50], Step [960/960], Training Accuracy: 0.9802, Training Loss: 0.0474\n",
            "Epoch [40/50], Step [240/960], Validation Accuracy: 0.9750, Validation Loss: 0.0223\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [41/50], Step [960/960], Training Accuracy: 0.9802, Training Loss: 0.0033\n",
            "Epoch [41/50], Step [240/960], Validation Accuracy: 0.9750, Validation Loss: 0.0002\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [42/50], Step [960/960], Training Accuracy: 0.9823, Training Loss: 0.3282\n",
            "Epoch [42/50], Step [240/960], Validation Accuracy: 0.9875, Validation Loss: 0.0002\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [43/50], Step [960/960], Training Accuracy: 0.9854, Training Loss: 0.0381\n",
            "Epoch [43/50], Step [240/960], Validation Accuracy: 0.9875, Validation Loss: 0.1441\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [44/50], Step [960/960], Training Accuracy: 0.9875, Training Loss: 0.1130\n",
            "Epoch [44/50], Step [240/960], Validation Accuracy: 0.9708, Validation Loss: 0.0841\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [45/50], Step [960/960], Training Accuracy: 0.9875, Training Loss: 0.0004\n",
            "Epoch [45/50], Step [240/960], Validation Accuracy: 0.9875, Validation Loss: 0.0058\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [46/50], Step [960/960], Training Accuracy: 0.9865, Training Loss: 0.0071\n",
            "Epoch [46/50], Step [240/960], Validation Accuracy: 0.9875, Validation Loss: 0.0008\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [47/50], Step [960/960], Training Accuracy: 0.9865, Training Loss: 0.0064\n",
            "Epoch [47/50], Step [240/960], Validation Accuracy: 0.9792, Validation Loss: 0.0002\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [48/50], Step [960/960], Training Accuracy: 0.9865, Training Loss: 0.0003\n",
            "Epoch [48/50], Step [240/960], Validation Accuracy: 0.9875, Validation Loss: 0.0203\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [49/50], Step [960/960], Training Accuracy: 0.9854, Training Loss: 0.0046\n",
            "Epoch [49/50], Step [240/960], Validation Accuracy: 0.9833, Validation Loss: 0.0012\n",
            "Current Learning Rate :  4.5e-05\n",
            "Epoch [50/50], Step [960/960], Training Accuracy: 0.9906, Training Loss: 0.0003\n",
            "Epoch [50/50], Step [240/960], Validation Accuracy: 0.9875, Validation Loss: 0.0000\n",
            "Current Learning Rate :  4.5e-05\n"
          ]
        }
      ],
      "source": [
        "model = LeNet5(num_classes).to(device)\n",
        "\n",
        "# Setting the loss function\n",
        "cost = nn.CrossEntropyLoss()\n",
        "\n",
        "# Setting the optimizer with the model parameters and learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, \n",
        "                            weight_decay=1e-5)\n",
        "\n",
        "# Adding ReduceLROnPlateau to vary learning rate. \n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', patience = 3)\n",
        "\n",
        "total_step = len(train_loader)\n",
        "model = model.double() \n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    train_samples = 0.0\n",
        "    valid_samples = 0.0\n",
        "    total, correct = 0 , 0\n",
        "    total_Val, correct_Val = 0 , 0\n",
        "    for i, (images, labels) in enumerate(train_loader, 0):  \n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = cost(outputs, labels.long())\n",
        "        \t\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()*images.size(0)\n",
        "        train_samples += images.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total+=labels.size(0)\n",
        "        correct+=(predicted==labels).sum().item()\n",
        "        train_accuracy = float(correct)/len(train_loader)\n",
        "\n",
        "        if (i+1) % 960 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.4f}, Training Loss: {:.4f}' \n",
        "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, train_accuracy, loss.item()))\n",
        "\n",
        "    model.eval()\n",
        "    for i, (images, labels) in enumerate(validation_loader, 0):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        output = model(images)\n",
        "        loss = cost(output, labels.long())\n",
        "\n",
        "        valid_loss += loss.item()*images.size(0)\n",
        "        train_loss += loss.item()*images.size(0)\n",
        "        valid_samples += images.size(0)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total_Val+=labels.size(0)\n",
        "        correct_Val+=(predicted==labels).sum().item()\n",
        "        val_accuracy = float(correct_Val)/len(validation_loader)\n",
        "        if (i+1) % 240 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Validation Accuracy: {:.4f}, Validation Loss: {:.4f}' \n",
        "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, val_accuracy, loss.item()))\n",
        "    curr_lr = optimizer.param_groups[0]['lr']\n",
        "    print('Current Learning Rate : ', curr_lr)\n",
        "\n",
        "    # Passing validation_loss as an argument for checking upto 5 number of epochs.\n",
        "    # patience = 5 means that the scheduler will check if validation loss does not\n",
        "    # decrease for 5 epochs, the scheduler decreases the learning rate\n",
        "    scheduler.step(valid_loss/len(validation_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8oBnQ0i4XbW",
        "outputId": "74fdf4c3-fa3b-4e36-9b3f-8982ce4c8014"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 63.25 %\n"
          ]
        }
      ],
      "source": [
        "Calculate_accuracy_TestDataset(model,test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsEocXRgzC_3"
      },
      "source": [
        "#                      ----------------                        **END OF NOTEBOOK**                       --------------"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "kMghgKyjE295",
        "e-2fGbJHudRk",
        "g9cNvSHeX-9x",
        "UNen03nYds1G",
        "IR0p6qmMzzQ5",
        "d_c8Cv7U38V2",
        "GA3OxGIzKW_f"
      ],
      "name": "agosavi_hshukla_bthulas_Project3_temp1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
